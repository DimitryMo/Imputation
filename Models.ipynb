{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import max_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, HuberRegressor, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, model=None, weights=None):\n",
    "    if model:\n",
    "        print(f'Model {model}')\n",
    "        \n",
    "    print(f'  MAE = {mean_absolute_error(y_true, y_pred, sample_weight=weights):.3f}')\n",
    "    print(f'  MSE = {mean_squared_error(y_true, y_pred, sample_weight=weights):.3f}')\n",
    "    print(f'  Max error = {max_error(y_true, y_pred):.3f}')\n",
    "    print(f'  R2 = {r2_score(y_true, y_pred, sample_weight=weights):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for grid search cv\n",
    "def cv_splitter(X):\n",
    "    for i in range(5):\n",
    "        start_ind = int(len(X)/10 * i)\n",
    "        split_ind = int(len(X)/10 * (i + 5))\n",
    "        end_ind = int(len(X)/10 * (i + 6))\n",
    "        train_ind = np.arange(start_ind, split_ind)\n",
    "        test_ind = np.arange(split_ind, end_ind)\n",
    "        yield train_ind, test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(df, to_drop=['TRADEDATE', 'SECID', 'VALUE', 'CLOSE', 'FACEUNIT', 'FACEVALUE', 'ISSUESIZE',\n",
    "                           'HIGH', 'LOW', 'delta_1', 'max_delta', 'delta_2', 'delta_3', 'delta_4', 'delta_5', 'delta_6',\n",
    "                            'delta_7', 'delta_8', 'delta_9', 'delta_10', 'TOMAT'\n",
    "                           ], trans=None):\n",
    "    \"\"\"\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    X = pd.get_dummies(df.drop(to_drop, axis=1), columns = ['TYPE', 'COUPON_TYPE'])\n",
    "    \n",
    "    if trans:\n",
    "        X_train = trans.fit_transform(X[:int(len(df)*3/4)])\n",
    "        X_test = trans.transform(X[int(len(df)*3/4):])\n",
    "        \n",
    "    else:\n",
    "        X_train = X[:int(len(df)*3/4)]\n",
    "        X_test = X[int(len(df)*3/4):]\n",
    "        \n",
    "    y_train = df['CLOSE'][:int(len(df)*3/4)]\n",
    "    y_test = df['CLOSE'][int(len(df)*3/4):]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred, weights):\n",
    "    mape = np.abs(y_true-y_pred)/np.abs(y_true)\n",
    "    return np.average(mape, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_cv(df, model, start_date, folder, scale_x=None, scale_y=None):\n",
    "    \n",
    "    date_str = str(start_date).split('T')[0]\n",
    "    df_today = df[df['TRADEDATE'] == start_date]\n",
    "    df_test = df_today.sample(int(len(df_today)/4), weights=df_today['WEIGHT'], random_state=6)\n",
    "    df_train = df[df['TRADEDATE'] <= start_date].drop(df_test.index)\n",
    "    \n",
    "    if scale_x:\n",
    "        X_train = scale_x.fit_transform(df_train.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'],\n",
    "                                                      axis=1).drop([f'delta{i}' for i in range(1,11)], axis=1))\n",
    "        X_test = scale_x.transform(df_test.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                                axis=1).drop([f'delta_{i}' for i in range(1,11)], axis=1))\n",
    "        X_train_return = scale_x.fit_transform(df_train.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                                             axis=1).drop([f'CLOSE_{i}' for i in range(1,11)], axis=1))\n",
    "        X_test_return = scale_x.transform(df_test.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                                             axis=1).drop([f'CLOSE_{i}' for i in range(1,11)], axis=1))\n",
    "    else:\n",
    "        X_train = df_train.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], axis=1)\n",
    "        X_test = df_test.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], axis=1)\n",
    "        \n",
    "    if scale_y:\n",
    "        y_train_delta = scale_y.fit_transform(df_train['DELTA'].values.reshape(-1,1)).reshape(-1,)\n",
    "        y_train_return = scale_y.fit_transform(df_train['RETURN'].values.reshape(-1,1)).reshape(-1,)\n",
    "        y_train_close = scale_y.fit_transform(df_train['CLOSE'].values.reshape(-1,1)).reshape(-1,)\n",
    "        y_test_close = scale_y.transform(df_test['CLOSE'].values.reshape(-1,1)).reshape(-1,)\n",
    "    else:\n",
    "        y_train_close = df_train['CLOSE']\n",
    "        y_test_close = df_test['CLOSE']\n",
    "        y_train_delta = df_train['DELTA']\n",
    "        y_train_return = df_train['RETURN']\n",
    "        \n",
    "    model.fit(X_train, y_train_close)\n",
    "    pred = model.predict(X_test)\n",
    "    pd.Series(pred).to_csv(f'{folder}/{date_str}_close.csv', index=False)\n",
    "    qual_close = mape(y_test_close, pred, df_test['WEIGHT'])\n",
    "    \n",
    "    model.fit(X_train, y_train_delta)\n",
    "    pred = model.predict(X_test) + X_test['CLOSE_1']\n",
    "    pd.Series(pred).to_csv(f'{folder}/{date_str}_delta.csv', index=False)\n",
    "    qual_delta = mape(y_test_close, pred, df_test['WEIGHT'])\n",
    "    \n",
    "    model.fit(X_train, y_train_return)\n",
    "    pred = model.predict(X_test) * X_test['CLOSE_1'] + X_test['CLOSE_1']\n",
    "    pd.Series(pred).to_csv(f'{folder}/{date_str}_return.csv', index=False)\n",
    "    qual_return = mape(y_test_close, pred, df_test['WEIGHT'])\n",
    "    \n",
    "    return qual_close, qual_delta, qual_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model, X_test, y_test, weights, close, target='CLOSE'):\n",
    "    imps = []\n",
    "    \n",
    "    if target == 'CLOSE':\n",
    "        mape_full = mape(model.predict(X_test), y_test, weights)\n",
    "        for i in range(X_test.shape[1]):\n",
    "            mape_curr = mape(model.predict(np.hstack((X_test.values[:, :i], np.zeros((len(X_test), 1)), \n",
    "                                                     X_test.values[:, i+1:]))), \n",
    "                             y_test, weights)\n",
    "            imps.append(mape_curr - mape_full)\n",
    "            \n",
    "    elif target == 'DELTA':\n",
    "        mape_full = mape(model.predict(X_test) + close, y_test, weights)\n",
    "        for i in range(X_test.shape[1]):\n",
    "            mape_curr = mape(model.predict(np.hstack((X_test.values[:, :i], np.zeros((len(X_test), 1)), \n",
    "                                                     X_test.values[:, i+1:]))) + close, \n",
    "                             y_test, weights)\n",
    "            imps.append(mape_curr - mape_full)\n",
    "    \n",
    "    elif target == 'RETURN':\n",
    "        mape_full = mape(model.predict(X_test) * close + close, y_test, weights)\n",
    "        for i in range(X_test.shape[1]):\n",
    "            mape_curr = mape(model.predict(np.hstack((X_test.values[:, :i], np.zeros((len(X_test),1)), \n",
    "                                                     X_test.values[:, i+1:]))) * close + close, \n",
    "                             y_test, weights)\n",
    "            imps.append(mape_curr - mape_full)\n",
    "            \n",
    "    return imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(df, model_price, model_return, folder, scale_x_price=None, scale_x_return=None, scale_y=None):\n",
    "    \n",
    "    quals_close = []\n",
    "    quals_delta = []\n",
    "    quals_return = []\n",
    "    imps_close = []\n",
    "    imps_delta = []\n",
    "    imps_return = []\n",
    "    \n",
    "    for start_ind, split_ind, end_ind in tqdm([(int(len(df[:381251])/10*i), int(len(df[:381251])/10*(i+5)), \n",
    "                                           int(len(df[:381251])/10 * (i + 6))) for i in range(5)]):\n",
    "        \n",
    "    \n",
    "        df_train = df[start_ind:split_ind]\n",
    "        df_test = df[split_ind:end_ind]\n",
    "        \n",
    "        X_train = df_train.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                axis=1).drop([f'delta_{i}' for i in range(2,11)], axis=1)\n",
    "        \n",
    "        X_test = df_test.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'],\n",
    "                              axis=1).drop([f'delta_{i}' for i in range(2,11)], axis=1)\n",
    "\n",
    "        X_train_return = df_train.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                                          axis=1).drop([f'CLOSE_{i}' for i in range(1,11)], axis=1)\n",
    "        \n",
    "        X_test_return = df_test.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                                          axis=1).drop([f'CLOSE_{i}' for i in range(1,11)], axis=1)\n",
    "\n",
    "        if scale_y:\n",
    "            y_train_close = scale_y.fit_transform(df_train['CLOSE'].values.reshape(-1,1)).reshape(-1,)\n",
    "            y_test_close = scale_y.transform(df_test['CLOSE'].values.reshape(-1,1)).reshape(-1,)\n",
    "            scale_close = scale_y\n",
    "            y_train_delta = scale_y.fit_transform(df_train['DELTA'].values.reshape(-1,1)).reshape(-1,)\n",
    "            y_test_delta = scale_y.transform(df_test['DELTA'].values.reshape(-1,1)).reshape(-1,)\n",
    "            scale_delta = scale_y\n",
    "            y_train_return = scale_y.fit_transform(df_train['RETURN'].values.reshape(-1,1)).reshape(-1,)\n",
    "            y_test_return = scale_y.transform(df_test['RETURN'].values.reshape(-1,1)).reshape(-1,)\n",
    "            scale_return = scale_y\n",
    "            test = df_test['CLOSE']\n",
    "\n",
    "        else:\n",
    "            y_train_close = df_train['CLOSE'].values\n",
    "            y_test_close = df_test['CLOSE'].values\n",
    "            y_train_delta = df_train['DELTA'].values\n",
    "            y_test_delta = df_test['DELTA'].values\n",
    "            y_train_return = df_train['RETURN'].values\n",
    "            y_test_return = df_test['RETURN'].values\n",
    "            \n",
    "\n",
    "        model_price.fit(X_train, y_train_close, model__sample_weight=df_train['WEIGHT'])\n",
    "        \n",
    "        if scale_y:\n",
    "            pred = scale_close.inverse_transform(model_price.predict(X_test))\n",
    "            pd.Series(pred).to_csv(f'{folder}/{start_ind}_close.csv', index=False)\n",
    "            qual_close = [mape(test, pred, df_test['WEIGHT']), \n",
    "                      mean_absolute_error(test, pred, sample_weight=df_test['WEIGHT'])]\n",
    "        else:\n",
    "            pred = model_price.predict(X_test)\n",
    "            pd.Series(pred).to_csv(f'{folder}/{start_ind}_close.csv', index=False)\n",
    "            qual_close = [mape(y_test_close, pred, df_test['WEIGHT']), \n",
    "                          mean_absolute_error(y_test_close, pred, sample_weight=df_test['WEIGHT'])]\n",
    "            \n",
    "        quals_close.append(qual_close)\n",
    "        imps_close.append(feature_importance(model_price, X_test, y_test_close, df_test['WEIGHT'], X_test['CLOSE_1'],\n",
    "                                             target='CLOSE'))\n",
    "\n",
    "        model_price.fit(X_train, y_train_delta, model__sample_weight=df_train['WEIGHT'])\n",
    "        \n",
    "        if scale_y:\n",
    "                pred = scale_delta.inverse_transform(model_price.predict(X_test)) + df_test['CLOSE_1']\n",
    "                pd.Series(pred).to_csv(f'{folder}/{start_ind}_delta.csv', index=False)\n",
    "                qual_delta = [mape(test, pred, df_test['WEIGHT']),\n",
    "                      mean_absolute_error(test, pred, sample_weight=df_test['WEIGHT'])]\n",
    "        else:                \n",
    "            pred = model_price.predict(X_test) + df_test['CLOSE_1']\n",
    "            pd.Series(pred).to_csv(f'{folder}/{start_ind}_delta.csv', index=False)\n",
    "            qual_delta = [mape(y_test_close, pred, df_test['WEIGHT']),\n",
    "                          mean_absolute_error(y_test_close, pred, sample_weight=df_test['WEIGHT'])]\n",
    "            \n",
    "        quals_delta.append(qual_delta)\n",
    "        imps_delta.append(feature_importance(model_price, X_test, y_test_delta, df_test['WEIGHT'], X_test['CLOSE_1'],\n",
    "                                             target='DELTA'))\n",
    "\n",
    "        model_return.fit(X_train_return, y_train_return, model__sample_weight=df_train['WEIGHT'])\n",
    "        \n",
    "        if scale_y:\n",
    "            pred = scale_return.inverse_transform(model_return.predict(X_test_return)) * df_test['CLOSE_1'] + df_test['CLOSE_1']\n",
    "            pd.Series(pred).to_csv(f'{folder}/{start_ind}_return.csv', index=False)\n",
    "            qual_return = [mape(test, pred, df_test['WEIGHT']),\n",
    "                       mean_absolute_error(test, pred, sample_weight=df_test['WEIGHT'])]\n",
    "        else:\n",
    "            pred = model_return.predict(X_test_return) * df_test['CLOSE_1'] + df_test['CLOSE_1']\n",
    "            pd.Series(pred).to_csv(f'{folder}/{start_ind}_return.csv', index=False)\n",
    "            qual_return = [mape(y_test_close, pred, df_test['WEIGHT']),\n",
    "                           mean_absolute_error(y_test_close, pred, sample_weight=df_test['WEIGHT'])]\n",
    "            \n",
    "        quals_return.append(qual_return)\n",
    "        imps_return.append(feature_importance(model_return, X_test_return, y_test_return, df_test['WEIGHT'], \n",
    "                                              X_test['CLOSE_1'], target='RETURN'))\n",
    "\n",
    "    return quals_close, quals_delta, quals_return, imps_close, imps_delta, imps_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full(df, model_price, model_return, folder, weights=True):\n",
    "    \n",
    "    df_train = df[:381251]\n",
    "    df_test = df[381251:]\n",
    "    \n",
    "    X_train = df_train.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                axis=1).drop([f'delta_{i}' for i in range(2,11)], axis=1)\n",
    "        \n",
    "    X_test = df_test.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'],\n",
    "                              axis=1).drop([f'delta_{i}' for i in range(2,11)], axis=1)\n",
    "\n",
    "    X_train_return = df_train.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                                          axis=1).drop([f'CLOSE_{i}' for i in range(1,11)], axis=1)\n",
    "        \n",
    "    X_test_return = df_test.drop(['CLOSE', 'DELTA', 'RETURN', 'TRADEDATE', 'WEIGHT'], \n",
    "                                                          axis=1).drop([f'CLOSE_{i}' for i in range(1,11)], axis=1)\n",
    "    \n",
    "    y_train_close = df_train['CLOSE'].values\n",
    "    y_test_close = df_test['CLOSE'].values\n",
    "    y_train_delta = df_train['DELTA'].values\n",
    "    y_test_delta = df_test['DELTA'].values\n",
    "    y_train_return = df_train['RETURN'].values\n",
    "    y_test_return = df_test['RETURN'].values\n",
    "    \n",
    "    if weights:\n",
    "        model_price.fit(X_train, y_train_close, model__sample_weight=df_train['WEIGHT'])\n",
    "    else:\n",
    "        model_price.fit(X_train, y_train_close)\n",
    "        \n",
    "    pred = model_price.predict(X_test)\n",
    "    pd.Series(pred).to_csv(f'{folder}/full_close.csv', index=False)\n",
    "    print(f'{folder} Close done')\n",
    "    \n",
    "    if weights:\n",
    "        model_price.fit(X_train, y_train_delta, model__sample_weight=df_train['WEIGHT'])\n",
    "    else:\n",
    "         model_price.fit(X_train, y_train_delta)\n",
    "            \n",
    "    pred = model_price.predict(X_test) + df_test['CLOSE_1']\n",
    "    pd.Series(pred).to_csv(f'{folder}/full_delta.csv', index=False)\n",
    "    print(f'{folder} Delta done')\n",
    "    \n",
    "    if weights:\n",
    "        model_return.fit(X_train_return, y_train_return, model__sample_weight=df_train['WEIGHT'])\n",
    "    else:\n",
    "        model_return.fit(X_train_return, y_train_return)\n",
    "        \n",
    "    pred = model_return.predict(X_test_return) * df_test['CLOSE_1'] + df_test['CLOSE_1']\n",
    "    pd.Series(pred).to_csv(f'{folder}/full_return.csv', index=False)\n",
    "    print(f'{folder} Return done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Pipeline([('model', LinearRegression())])\n",
    "ridge_close = Pipeline([('scaler', MinMaxScaler()), ('model', Ridge(alpha=0.01, max_iter=5000))])\n",
    "ridge_return = Pipeline([('scaler', MinMaxScaler()), ('model', Ridge(alpha=10,  max_iter=5000))])\n",
    "lasso_close = Pipeline([('scaler', StandardScaler()),('model', Lasso(alpha=0.01,  max_iter=5000))])\n",
    "lasso_return = Pipeline([('scaler', StandardScaler()),('model', Lasso(alpha=0.001,  max_iter=5000))])\n",
    "huber_close = Pipeline([('scaler', StandardScaler()), ('model', HuberRegressor(alpha=0.001, epsilon=1.01, max_iter=5000))])\n",
    "huber_return = Pipeline([('scaler', MinMaxScaler()), ('model', HuberRegressor(alpha=1, epsilon=1.01,  max_iter=5000))])\n",
    "elastic_close = Pipeline([('scaler', StandardScaler()), ('model', ElasticNet(alpha=0.01, l1_ratio=0.9,  max_iter=5000))])\n",
    "elastic_return = Pipeline([('scaler', StandardScaler()), ('model', ElasticNet(alpha=0.001, l1_ratio=0.6,  max_iter=5000))])\n",
    "rf = Pipeline([('model', RandomForestRegressor(random_state=6, ccp_alpha=0.005, max_depth=30, n_estimators=100))])\n",
    "\n",
    "for model_close, model_return, folder in [(lr, lr, 'lr_pred'), (ridge_close, ridge_return, 'ridge_pred'),\n",
    "                                 (lasso_close, lasso_return, 'lasso_pred'), (huber_close, huber_return, 'huber_pred'),\n",
    "                                 (elastic_close, elastic_return, 'elastic_pred'), (rf, rf, 'rf_pred')]:\n",
    "    predict_full(df_clean, model_close, model_return, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_close = Pipeline([('model', AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=7, random_state=6),\n",
    "                                                      n_estimators=100, learning_rate=0.001))])\n",
    "adaboost_return = Pipeline([('model', AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=6, random_state=6),\n",
    "                                                      n_estimators=100, learning_rate=0.01))])\n",
    "gradboost_close = Pipeline([('model', GradientBoostingRegressor(max_depth=6, loss='huber', n_estimators=100))])\n",
    "gradboost_close = Pipeline([('model', GradientBoostingRegressor(max_depth=7, loss='huber', n_estimators=50))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predict_full(df_clean, adaboost_close, adaboost_return, 'Predictions/adaboost_pred', weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predict_full(df_clean, gradboost_close, gradboost_close, 'Predictions/gradboost_pred', weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_return = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_return['RETURN'] = (df_for_return['CLOSE'] - df_for_return['CLOSE_1'])/df_for_return['CLOSE_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_return['delta_1'] = (df_for_return['CLOSE'] - df_for_return['CLOSE_1'])/df_for_return['CLOSE_1']\n",
    "df_for_return['delta_2'] = (df_for_return['CLOSE_1'] - df_for_return['CLOSE_2'])/df_for_return['CLOSE_2']\n",
    "df_for_return['delta_3'] = (df_for_return['CLOSE_2'] - df_for_return['CLOSE_3'])/df_for_return['CLOSE_3']\n",
    "df_for_return['delta_4'] = (df_for_return['CLOSE_3'] - df_for_return['CLOSE_4'])/df_for_return['CLOSE_4']\n",
    "df_for_return['delta_5'] = (df_for_return['CLOSE_4'] - df_for_return['CLOSE_5'])/df_for_return['CLOSE_5']\n",
    "df_for_return['delta_6'] = (df_for_return['CLOSE_5'] - df_for_return['CLOSE_6'])/df_for_return['CLOSE_6']\n",
    "df_for_return['delta_7'] = (df_for_return['CLOSE_6'] - df_for_return['CLOSE_7'])/df_for_return['CLOSE_7']\n",
    "df_for_return['delta_8'] = (df_for_return['CLOSE_7'] - df_for_return['CLOSE_8'])/df_for_return['CLOSE_8']\n",
    "df_for_return['delta_9'] = (df_for_return['CLOSE_8'] - df_for_return['CLOSE_9'])/df_for_return['CLOSE_9']\n",
    "df_for_return['delta_10'] = (df_for_return['CLOSE_9'] - df_for_return['CLOSE_10'])/df_for_return['CLOSE_10']\n",
    "\n",
    "df_for_return['max_delta'] = df_for_return[[f'delta_{i}' for i in range(1, 11)]].abs().max(axis=1)\n",
    "\n",
    "df_for_return_clean = df_for_return[df_for_return['max_delta'].abs() < 10].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_return(df, to_drop=['TRADEDATE', 'SECID', 'VALUE', 'FACEUNIT', 'FACEVALUE', 'ISSUESIZE',\n",
    "                           'HIGH', 'LOW', 'TOMAT'\n",
    "                           ], trans=None):\n",
    "    \"\"\"\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    X = pd.get_dummies(df.drop(to_drop, axis=1), columns = ['TYPE', 'COUPON_TYPE'])\n",
    "    \n",
    "    if trans:\n",
    "        X_train = trans.fit_transform(X[:int(len(df)*3/4)])\n",
    "        X_test = trans.transform(X[int(len(df)*3/4):])\n",
    "        \n",
    "    else:\n",
    "        X_train = X.drop('RETURN', axis=1)[:int(len(df)*3/4)]\n",
    "        X_test = X.drop('RETURN', axis=1)[int(len(df)*3/4):]\n",
    "        \n",
    "    y_train = df['RETURN'][:int(len(df)*3/4)]\n",
    "    y_test = df['RETURN'][int(len(df)*3/4):]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_return_clean = df_for_return_clean.drop(\n",
    "    [f'CLOSE_{i}' for i in range(1, 11)], axis=1).drop(['CLOSE', 'max_delta', 'delta_1', 'WEIGHT'], axis=1)\n",
    "\n",
    "df_for_return_clean[[f'DIST_{i}' for i in range(1, 11)]] =\\\n",
    "np.log(1 + df_for_return_clean[[f'DIST_{i}' for i in range(1, 11)]])\n",
    "\n",
    "df_for_return_clean[[f'VALUE_{i}' for i in range(1, 11)]] =\\\n",
    "np.log(1 + df_for_return_clean[[f'VALUE_{i}' for i in range(1, 11)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_split_return(df_for_return_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "huber = HuberRegressor()\n",
    "rf = RandomForestRegressor(random_state=6, criterion='mae', n_jobs=2, max_depth=20)\n",
    "gb = GradientBoostingRegressor(loss='lad', random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "get_metrics(y_test, lr.predict(X_test), model='RETURN')\n",
    "get_metrics(df['CLOSE'][X_test.index], lr.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE')\n",
    "get_metrics(df['CLOSE'][X_test.index], lr.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE_WEIGHT', weights=df['WEIGHT'][X_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huber.fit(X_train, y_train)\n",
    "get_metrics(y_test, huber.predict(X_test), model='RETURN')\n",
    "get_metrics(df['CLOSE'][X_test.index], huber.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE')\n",
    "get_metrics(df['CLOSE'][X_test.index], huber.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE_WEIGHT', weights=df['WEIGHT'][X_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)\n",
    "get_metrics(y_test, rf.predict(X_test), model='RETURN')\n",
    "get_metrics(df['CLOSE'][X_test.index], rf.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE')\n",
    "get_metrics(df['CLOSE'][X_test.index], rf.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE_WEIGHT', weights=df['WEIGHT'][X_test.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gb.fit(X_train, y_train)\n",
    "get_metrics(y_test, gb.predict(X_test), model='RETURN')\n",
    "get_metrics(df['CLOSE'][X_test.index], gb.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE')\n",
    "get_metrics(df['CLOSE'][X_test.index], gb.predict(X_test) * df['CLOSE_1'][X_test.index] + df['CLOSE_1'][X_test.index],\n",
    "           model='PRICE_WEIGHT', weights=df['WEIGHT'][X_test.index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
