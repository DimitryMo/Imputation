{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBE-K0i0k23k"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import max_error, mean_absolute_error, mean_squared_error, r2_score \n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PolynomialFeatures\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CORP_prices_6_years_to_predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default filtering and date to dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd46FgJkk23x"
   },
   "outputs": [],
   "source": [
    "# Remove defaulted Bonds\n",
    "defaults = pd.read_csv('default_data.csv')\n",
    "defaults.replace('-', np.NaN, inplace=True)\n",
    "defaults['Def_date'] = pd.to_datetime(defaults['Def_date'], format='%d.%m.%Y')\n",
    "defaults['Date_repay'] = pd.to_datetime(defaults['Date_repay'], format='%d.%m.%Y')\n",
    "defaults['Repay_lag'] = defaults['Date_repay'] - defaults['Def_date']\n",
    "defaults['Repay_lag'] = defaults['Repay_lag'].apply(lambda x:x.days)\n",
    "real_defaults = defaults[(defaults['Obl_type'] != 'No Default') & (defaults['Def_type'] != 'технический дефолт')]\n",
    "df['TRADEDATE'] = pd.to_datetime(df['TRADEDATE'], format='%Y-%m-%d')\n",
    "\n",
    "full_drop = real_defaults[(real_defaults['Def_date'] < pd.to_datetime('2017-01-01', format='%Y-%m-%d')) & \n",
    "(real_defaults['Date_repay'].isna())]['SECID'].unique() #убрал всех с дефолтами до 2017 и без repay по обязательствам\n",
    "df = df[~df['SECID'].isin(full_drop)]\n",
    "\n",
    "full_drop_1 = real_defaults[(real_defaults['Def_date'] < pd.to_datetime('2017-01-01', format='%Y-%m-%d')) & \n",
    "(real_defaults['Repay_lag']>100)]['SECID'].unique() #убрал всех с дефолтами до 2017и с долгим repay по обязательствам \n",
    "df = df[~df['SECID'].isin(full_drop_1)]\n",
    "\n",
    "# Для дефолтов после 2017 убираются все наблюдения от недели до дефолта и дальше для нужной облигации\n",
    "sorted_defaults = real_defaults[(real_defaults['Def_date'] > pd.to_datetime('2017-01-01', format='%Y-%m-%d'))].\\\n",
    "        sort_values(by='Def_date').groupby('SECID').first()\n",
    "sorted_defaults['remove_date'] = sorted_defaults['Def_date'] - pd.Timedelta(7, 'd')\n",
    "for secid in sorted_defaults.index:\n",
    "    df = df[~((df['SECID'] == secid) & (df['TRADEDATE'] > sorted_defaults.loc[secid, 'remove_date']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGKdU8Ukk23y"
   },
   "outputs": [],
   "source": [
    "# Convert DATE to DIST (lag from observation date)\n",
    "df['DATE_1'] = pd.to_datetime(df['DATE_1'], format='%Y-%m-%d')\n",
    "df['DATE_2'] = pd.to_datetime(df['DATE_2'], format='%Y-%m-%d')\n",
    "df['DATE_3'] = pd.to_datetime(df['DATE_3'], format='%Y-%m-%d')\n",
    "df['DATE_4'] = pd.to_datetime(df['DATE_4'], format='%Y-%m-%d')\n",
    "df['DATE_5'] = pd.to_datetime(df['DATE_5'], format='%Y-%m-%d')\n",
    "\n",
    "for i in range(1, 6):\n",
    "    df[f'DIST_{i}'] = (df['TRADEDATE'] - df[f'DATE_{i}']).apply(lambda x:x.days)\n",
    "\n",
    "df.drop(['DATE_1', 'DATE_2', 'DATE_3', 'DATE_4', 'DATE_5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0QtUgRXk232"
   },
   "source": [
    "## Main feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ps4AX8NMk233"
   },
   "outputs": [],
   "source": [
    "df['TRADEDATE'] = pd.to_datetime(df['TRADEDATE'])\n",
    "df['LN_SIZE'] = np.log(df['ISSUESIZE'])\n",
    "df['TOMAT_YEARS'] = df['TOMAT']/365\n",
    "df['RETURN'] = (df['CLOSE'] - df['CLOSE_1'])/df['CLOSE_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lm0a3nNEk234"
   },
   "outputs": [],
   "source": [
    "#VAR5, VAR10, ES5, ES10 - out of 40 observations\n",
    "df = df.join(df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['RETURN'].rolling(40).apply(\n",
    "        raw=True, func=lambda y: np.sort(y)[1])), on=['SECID','TRADEDATE'], rsuffix='_VAR5')\n",
    "\n",
    "df = df.join(df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['RETURN'].rolling(40).apply(\n",
    "        raw=True, func=lambda y: np.sort(y)[3])), on=['SECID','TRADEDATE'], rsuffix='_VAR10')\n",
    "\n",
    "df = df.join(df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['RETURN'].rolling(40).apply(\n",
    "        raw=True, func=lambda y: np.sort(y)[:2].mean())), on=['SECID','TRADEDATE'], rsuffix='_ES5')\n",
    "\n",
    "df = df.join(df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['RETURN'].rolling(40).apply(\n",
    "        raw=True, func=lambda y: np.sort(y)[:4].mean())), on=['SECID','TRADEDATE'], rsuffix='_ES10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CeHyWBtfk234"
   },
   "outputs": [],
   "source": [
    "# ILLIQ  - covariation of daily price changes by month\n",
    "df['delta_now'] = np.log(df['CLOSE']) - np.log(df['CLOSE_1'])\n",
    "df['delta_prev'] = np.log(df['CLOSE_1']) - np.log(df['CLOSE_2'])\n",
    "\n",
    "df['deltas'] = [[i,j] for i,j in zip(df['delta_now'], df['delta_prev'])]\n",
    "\n",
    "out = [list(window) for window in\n",
    "       df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['deltas'].rolling('30d'))]\n",
    "\n",
    "df_gr = df.groupby(['SECID', 'TRADEDATE']).last().reset_index()\n",
    "\n",
    "out_unpacked = [i for j in out for i in j]\n",
    "\n",
    "covs = [np.cov([i for i in j], rowvar=False)[0][1] if len(j)>1 else np.cov([i for i in j], rowvar=False).item()\n",
    " for j in tqdm(out_unpacked)]\n",
    "\n",
    "df_gr['covs'] = covs\n",
    "\n",
    "df_gr['ILLIQ'] = -df_gr['covs']\n",
    "\n",
    "df = df.join(df_gr.set_index(['TRADEDATE', 'SECID'])['ILLIQ'], on=['TRADEDATE', 'SECID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nkZUEixk236"
   },
   "outputs": [],
   "source": [
    "# Roll measure of illiquidity\n",
    "df['RETURN_prev'] = (df['CLOSE_1'] - df['CLOSE_2'])/df['CLOSE_2']\n",
    "\n",
    "\n",
    "df['returns'] =  [[i,j] for i,j in zip(df['RETURN'].fillna(0), df['RETURN_prev'].fillna(0))]\n",
    "out = [list(window) for window in\n",
    "       df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['returns'].rolling('30d'))]\n",
    "\n",
    "out_unpacked = [i for j in out for i in j]\n",
    "\n",
    "covs_return = [np.cov([i for i in j], rowvar=False)[0][1] if len(j)>1 else np.cov([i for i in j], rowvar=False).item()\n",
    " for j in tqdm(out_unpacked)]\n",
    "\n",
    "df_gr['covs_return'] = covs_return\n",
    "\n",
    "df_gr['ROLL'] = ((df_gr['covs_return'] < 0).astype(int) * -df_gr['covs_return'])**0.5\n",
    "\n",
    "df = df.join(df_gr.reset_index().set_index(['TRADEDATE', 'SECID'])['ROLL'], on=['TRADEDATE', 'SECID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wO6PMd4Ck237"
   },
   "outputs": [],
   "source": [
    "# P_HighLow\n",
    "df_2 = df\n",
    "\n",
    "df_2['day_of_week'] = df_2['TRADEDATE'].apply(lambda x:x.dayofweek)\n",
    "\n",
    "df_2['day_of_week_prev'] = df_2.groupby(['SECID'])['day_of_week'].shift()\n",
    "\n",
    "df_2['prev_high'] = df_2.groupby(['SECID'])['HIGH'].shift()\n",
    "\n",
    "df_2['prev_low'] = df_2.groupby(['SECID'])['HIGH'].shift()\n",
    "\n",
    "df_2['consecutive'] = (((df_2['day_of_week'] == 0) & (df_2['day_of_week_prev'] == 4))| (df_2['DIST_1'] == 1)).astype(int)\n",
    "\n",
    "df_2 = df_2[df_2['consecutive'] == 1]\n",
    "\n",
    "df_2 = df_2[df_2['prev_high'].notna()]\n",
    "\n",
    "df_2['gamma'] = np.log(df_2[['HIGH', 'prev_high']].max(axis=1)/df_2[['LOW', 'prev_low']].min(axis=1))**2\n",
    "df_2['beta'] = (np.log(df_2['HIGH']/df_2['LOW']) + np.log(df_2['prev_high']/df_2['prev_low']))**2\n",
    "df_2['alpha'] = (2 * df_2['beta'] ** 0.5 - df_2['beta'] ** 0.5)/(2 - 2 * 2 ** 0.5) - np.sqrt(df_2['gamma']/(3 - 2 * 2 ** 0.5))\n",
    "df_2['P_HIGHLOW'] = 2 * (np.exp(df_2['alpha']) - 1)/(1 + np.exp(df_2['alpha']))\n",
    "\n",
    "df = df.join(df_2.set_index(['TRADEDATE', 'SECID'])['P_HIGHLOW'], on=['TRADEDATE', 'SECID'])\n",
    "df['P_HIGHLOW'] = df.groupby('SECID')['P_HIGHLOW'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRavB77ck237"
   },
   "outputs": [],
   "source": [
    "# P_ZEROS, df_1 = CORP_prices_full\n",
    "days_no_trades = df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['VALUE'].rolling('30d').apply(raw=True, \n",
    "                                                                                   func=lambda y:(y == 0).sum()))\n",
    "\n",
    "df_3 = df.join(days_no_trades.reset_index().set_index(['SECID', 'TRADEDATE'])['VALUE'], on=['SECID', 'TRADEDATE'], \n",
    "               rsuffix='_r')\n",
    "\n",
    "df_3 = df_3[~df_3.index.duplicated()]\n",
    "\n",
    "df_3 = df_3.rename(columns={'VALUE_r':'days_no_trade'})\n",
    "\n",
    "df = df.join(df_3.set_index(['SECID','TRADEDATE'])['days_no_trade'], on=['SECID','TRADEDATE'])\n",
    "\n",
    "df = df.join(df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')['RETURN'].rolling('30d').apply(\n",
    "                raw=True, func=lambda y: (y == 0).sum())), on=['SECID', 'TRADEDATE'], rsuffix='_no_count')\n",
    "\n",
    "df['P_ZEROS'] = (df['RETURN_no_count'] + df['days_no_trade'])/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_43mZDp6k237"
   },
   "outputs": [],
   "source": [
    "# AMIHUD and STD_AMIHUDS\n",
    "out_returns_volumes = [list(window) for window in\n",
    "       df.groupby('SECID').apply(lambda x: x.set_index('TRADEDATE')[['RETURN', 'VALUE']].rolling('30d'))]\n",
    "\n",
    "ahimuds = [(np.abs(out_returns_volumes[j][i]['RETURN'])/out_returns_volumes[j][i]['VALUE']).mean() \n",
    " for j in tqdm(range(len(out_returns_volumes))) for i in range(len(out_returns_volumes[j]))]\n",
    "\n",
    "std_ahimuds = [(np.abs(out_returns_volumes[j][i]['RETURN'])/out_returns_volumes[j][i]['VALUE']).std()\n",
    " for j in tqdm(range(len(out_returns_volumes))) for i in range(len(out_returns_volumes[j]))]\n",
    "\n",
    "df_gr = df.groupby(['SECID', 'TRADEDATE']).last()\n",
    "\n",
    "df_gr['AMIHUD'] = ahimuds\n",
    "df_gr['STD_AMIHUD'] = std_ahimuds\n",
    "\n",
    "df = df.join(df_gr[['AMIHUD', 'STD_AMIHUD']], on=['SECID', 'TRADEDATE'])\n",
    "\n",
    "df['STD_AMIHUD'] = df['STD_AMIHUD'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPOVL8C2k238"
   },
   "outputs": [],
   "source": [
    "# VOL, SKEW, KURT\n",
    "df = df.join(df.groupby('SECID').apply(lambda x:x.set_index('TRADEDATE').rolling('60d')['CLOSE'].apply(\n",
    "    raw=True, func=lambda y: np.var(y))), on=['SECID','TRADEDATE'], rsuffix='_VOL')\n",
    "\n",
    "df = df.join(df.groupby('SECID').apply(lambda x:x.set_index('TRADEDATE').rolling('60d')['CLOSE'].apply(\n",
    "    raw=True, func=lambda y: kurtosis(y, axis=None))), on=['SECID','TRADEDATE'], rsuffix='_KURT')\n",
    "\n",
    "df = df.join(df.groupby('SECID').apply(lambda x:x.set_index('TRADEDATE').rolling('60d')['CLOSE'].apply(\n",
    "    raw=True, func=lambda y: skew(y, axis=None))), on=['SECID','TRADEDATE'], rsuffix='_SKEW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Government bonds index data\n",
    "df_ofz = pd.read_csv('OFZ_index.csv')\n",
    "\n",
    "df_ofz['TRADEDATE'] = pd.to_datetime(df_ofz['TRADEDATE'])\n",
    "\n",
    "df = df.join(df_ofz.set_index('TRADEDATE'), on='TRADEDATE')\n",
    "\n",
    "df['OFZ_index'] = (df['TOMAT_YEARS'] < 1) * df['RUGBITR1Y'] + (df['TOMAT_YEARS'].between(1, 3) * df['RUGBITR3Y']) + \\\n",
    "(df['TOMAT_YEARS'].between(3, 5, inclusive=False) * df['RUGBITR5Y']) + (df['TOMAT_YEARS'] >=5) * df['RUGBITR5+']\n",
    "\n",
    "df['PREV_DATE'] = df['TRADEDATE'] - df['DIST_1'] * pd.Timedelta('1d')\n",
    "\n",
    "df = df.join(df_ofz.set_index('TRADEDATE').shift(), on='TRADEDATE', rsuffix='_PREV')\n",
    "\n",
    "df['OFZ_index_prev'] = (df['TOMAT_YEARS'] < 1) * df['RUGBITR1Y_PREV'] + \\\n",
    "(df['TOMAT_YEARS'].between(1, 3) * df['RUGBITR3Y_PREV']) + \\\n",
    "(df['TOMAT_YEARS'].between(3, 5, inclusive=False) * df['RUGBITR5Y_PREV']) + \\\n",
    "(df['TOMAT_YEARS'] >=5) * df['RUGBITR5+_PREV']\n",
    "\n",
    "df['OFZ_DELTA'] = df['OFZ_index'] - df['OFZ_index_prev']\n",
    "df['OFZ_DELTA'] = df['OFZ_DELTA']/df['OFZ_index_prev']\n",
    "\n",
    "df.drop(['RUGBITR1Y', 'RUGBITR3Y', 'RUGBITR5Y', 'RUGBITR5+', 'RUGBITR1Y_PREV', 'RUGBITR3Y_PREV', 'RUGBITR5Y_PREV', \n",
    "        'RUGBITR5+_PREV'], axis=1,inplace=True)\n",
    "\n",
    "# add CB rate data\n",
    "cbr = pd.read_excel('cbrate.xlsx')\n",
    "\n",
    "cbr['TRADEDATE'] = pd.to_datetime(cbr['TRADEDATE'])\n",
    "cbr_new = pd.DataFrame(pd.Index(df['TRADEDATE'].unique())).join(cbr.set_index('TRADEDATE'), on=0, how='outer')\n",
    "cbr_new = cbr_new.fillna(method='ffill')\n",
    "\n",
    "df = df.join(cbr_new.set_index('TRADEDATE'), on='TRADEDATE')\n",
    "\n",
    "df = df.join(cbr_new.set_index('TRADEDATE'), on='PREV_DATE', rsuffix='_PREV')\n",
    "\n",
    "df['DELTA_CBRATE'] = df['CBRATE'] - df['CBRATE_PREV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vwap and twap\n",
    "df['VWAP'] = (df['VALUE_1'] * df['CLOSE_1'] + df['VALUE_2'] * df['CLOSE_2'] + df['VALUE_3'] * df['CLOSE_3'] + \n",
    "df['VALUE_4'] * df['CLOSE_4'] + df['VALUE_5'] * df['CLOSE_5'])/df[['VALUE_1', 'VALUE_2', 'VALUE_3',\n",
    "                                                                   'VALUE_4', 'VALUE_5']].sum(axis=1)\n",
    "\n",
    "df['TWAP'] = (df['CLOSE_1'] / df['DIST_1'] + df['CLOSE_2']/df['DIST_2'] + df['CLOSE_3']/df['DIST_3'] + \n",
    "df['CLOSE_4'] / df['DIST_4'] + df['CLOSE_5']/df['DIST_5']) / (1/df['DIST_1'] + 1/df['DIST_2'] + 1/df['DIST_3'] +\n",
    "                                                             1/df['DIST_4'] + 1/df['DIST_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0P2XwjY6k238"
   },
   "outputs": [],
   "source": [
    "df['P_HIGHLOW'] = df['P_HIGHLOW'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxKpEzmLk239"
   },
   "outputs": [],
   "source": [
    "df['ILLIQ'] = df['ILLIQ'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcJTvFG_k24B"
   },
   "source": [
    "## Calclulate Betas (market, default, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('CORP_prices_6_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLM2Bsurk24B"
   },
   "outputs": [],
   "source": [
    "#Prepare index and gcurve data\n",
    "corp_index = pd.read_csv('CORP_index.csv')\n",
    "g_curve = pd.read_csv('g_curves.csv')\n",
    "ofz_index = pd.read_csv('OFZ_index.csv')\n",
    "\n",
    "corp_index['TRADEDATE'] = pd.to_datetime(corp_index['TRADEDATE'])\n",
    "ofz_index['TRADEDATE'] = pd.to_datetime(ofz_index['TRADEDATE'])\n",
    "\n",
    "corp_index = corp_index.drop_duplicates()\n",
    "corp_index = corp_index[corp_index['TRADEDATE'] <= '2021-01-01']\n",
    "ofz_index = ofz_index[ofz_index['TRADEDATE'] <= '2021-01-01']\n",
    "\n",
    "ofz_index['TRADEDATE'] = pd.to_datetime(ofz_index['TRADEDATE'])\n",
    "corp_index['TRADEDATE'] = pd.to_datetime(corp_index['TRADEDATE'])\n",
    "g_curve['DATE'] = pd.to_datetime(g_curve['DATE'])\n",
    "\n",
    "\n",
    "corp_index['RETURN_3Y'] = (corp_index['RUCBTR3Y'] - corp_index['RUCBTR3Y'].shift())/corp_index['RUCBTR3Y'].shift()\n",
    "\n",
    "corp_index['RETURN_1Y'] = (corp_index['RUCBITR1Y'] - corp_index['RUCBITR1Y'].shift())/corp_index['RUCBTR3Y'].shift()\n",
    "\n",
    "corp_index['RETURN_5Y'] = (corp_index['RUCBTR5Y'] - corp_index['RUCBTR5Y'].shift())/corp_index['RUCBTR3Y'].shift()\n",
    "\n",
    "corp_index['RETURN_3+'] = (corp_index['RUCBITR3+'] - corp_index['RUCBITR3+'].shift())/corp_index['RUCBTR3Y'].shift()\n",
    "\n",
    "g_curve['0.25'] = (1 + g_curve['0.25']/100) ** (1/365) - 1\n",
    "g_curve['5'] = (1 + g_curve['5']/100) ** (1/365) - 1\n",
    "g_curve['10'] = (1 + g_curve['10']/100) ** (1/365) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvM0T88Ak24C"
   },
   "outputs": [],
   "source": [
    "#join index returns and g_curve to df\n",
    "df_1['years_tomat'] = df_1['TOMAT']/365\n",
    "\n",
    "df_1['TRADEDATE'] = pd.to_datetime(df_1['TRADEDATE'])\n",
    "\n",
    "df_1 = df_1.join(corp_index.set_index('TRADEDATE')[['RUCBITR1Y', 'RUCBTR3Y', 'RUCBTR5Y', 'RUCBITR3+']], on='TRADEDATE')\n",
    "\n",
    "df_1['corp_index'] = (df_1['years_tomat'] < 1) * df_1['RUCBITR1Y'] \\\n",
    "+ df_1['years_tomat'].between(1, 3) * df_1['RUCBTR3Y']\\\n",
    "+ df_1['years_tomat'].between(3, 5, inclusive=False) * df_1['RUCBTR5Y']\\\n",
    "+ (df_1['years_tomat'] >= 5)  * df_1['RUCBITR3+']\n",
    "\n",
    "df_1.drop(['RUCBITR1Y', 'RUCBTR3Y', 'RUCBTR5Y', 'RUCBITR3+'], axis=1, inplace=True)\n",
    "\n",
    "df_1 = df_1.join(g_curve.set_index('DATE')[['0.25', '5']], on='TRADEDATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aR78XCoYk24C"
   },
   "outputs": [],
   "source": [
    "#calculate daily return for corp index and bond\n",
    "df_1['return_daily'] = ((df_1['CLOSE'] - df_1['CLOSE_1'])/df_1['CLOSE_1'] + 1)**(1/df_1['DIST_1']) - 1\n",
    "\n",
    "df_1['return_corp_index'] = ((df_1['corp_index'] - df_1.groupby('SECID')['corp_index'].shift())/\n",
    "df_1.groupby('SECID')['corp_index'].shift() + 1)**(1/df_1['DIST_1']) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LXcJAlyk24C"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "df_gr = df_1.groupby(['SECID', 'TRADEDATE']).last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop return_daily to stay in normal range\n",
    "df_1['return_daily'] = \\\n",
    "(df_1['return_daily'] > df_1['return_daily'].quantile(0.95)).astype(int) * df_1['return_daily'].quantile(0.95) + \\\n",
    "(df_1['return_daily'] < df_1['return_daily'].quantile(0.05)).astype(int) * df_1['return_daily'].quantile(0.05) +  \\\n",
    "(df_1['return_daily'].between(df_1['return_daily'].quantile(0.05), df_1['return_daily'].quantile(0.95))).astype(int) *\\\n",
    "df_1['return_daily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t14tGihZk24C"
   },
   "outputs": [],
   "source": [
    "#ordinary beta\n",
    "def calculate_beta_ord(x, lr):\n",
    "    return lr.fit((x['return_corp_index'].fillna(0).values - x['0.25'].values).reshape(-1, 1),\n",
    "                  x['return_daily'].fillna(0) - x['0.25']\n",
    "                 ).coef_.item()\n",
    "\n",
    "#calculate ordinary beta for bonds\n",
    "for_beta_ord = [calculate_beta_ord(window, lr) for windows in tqdm(df_1.groupby('SECID').apply(\n",
    "lambda x:x.set_index('TRADEDATE')[['return_daily', 'return_corp_index', '0.25']].rolling(40)))\n",
    "               for window in list(windows)]\n",
    "\n",
    "df_gr = df_1.groupby(['SECID', 'TRADEDATE']).last()\n",
    "df_gr['BETA_ORD'] = for_beta_ord\n",
    "df_1 = df_1.join(df_gr['BETA_ORD'], on=['SECID', 'TRADEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MI_mDcXNk24D"
   },
   "outputs": [],
   "source": [
    "#beta default factor\n",
    "\n",
    "#calculate default factor\n",
    "\n",
    "df_1['DEF'] = df_1['RETURN_3+'] - df_1['5']\n",
    "\n",
    "def calculate_beta_def(x, lr):\n",
    "    return lr.fit(np.stack([(x['return_corp_index'].fillna(0) - x['0.25']).values, x['DEF'].values]).reshape(-1,2),\n",
    "           x['return_daily'].fillna(0) - x['0.25']).coef_[1]\n",
    "\n",
    "for_beta_def = [calculate_beta_def(window, lr) for windows in tqdm(df_1.groupby('SECID').apply(\n",
    "lambda x:x.set_index('TRADEDATE')[['return_daily', 'return_corp_index', 'DEF', '0.25']].rolling(40)))\n",
    "               for window in list(windows)]\n",
    "\n",
    "df_gr['BETA_DEF'] = for_beta_def\n",
    "df_1 = df_1.join(df_gr['BETA_DEF'], on=['SECID', 'TRADEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta term\n",
    "def calculate_beta_term(x, lr):\n",
    "    return lr.fit(x[['mkt', 'TERM']], \n",
    "           x['return_daily'].fillna(0) - x['0.25']).coef_[1]\n",
    "\n",
    "df_1['mkt'] = df_1['return_corp_index'].fillna(0) - df_1['0.25']\n",
    "\n",
    "df_1['TERM'] = df_1['10'] - df_1['0.25']\n",
    "\n",
    "for_beta_term = [calculate_beta_term(window, lr) for windows in tqdm(df_1.groupby('SECID').apply(\n",
    "lambda x:x.set_index('TRADEDATE')[['return_daily', 'mkt', 'TERM', '0.25']].rolling(40)))\n",
    "                for window in list(windows)]\n",
    "\n",
    "df_gr['BETA_TERM'] = for_beta_term\n",
    "df_1 = df_1.join(df_gr['BETA_TERM'], on=['SECID', 'TRADEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beta drf\n",
    "def calculate_drf(x):\n",
    "    x_low = x[x['RETURN_VAR10'] >= x['RETURN_VAR10'].quantile(0.8)]\n",
    "    x_high = x[x['RETURN_VAR10'] <= x['RETURN_VAR10'].quantile(0.2)]\n",
    "    return (x_high['return_daily'] * x_high['VALUE_1']).sum()/x_high['VALUE_1'].sum() -\\\n",
    "    (x_low['return_daily'] * x_low['VALUE_1']).sum()/x_low['VALUE_1'].sum()\n",
    "\n",
    "drf = df_1.groupby('TRADEDATE').apply(calculate_drf).fillna(0)\n",
    "drf.columns = ['DRF']\n",
    "drf.name = 'DRF'\n",
    "df_1 = df_1.join(drf, on='TRADEDATE')\n",
    "\n",
    "def calculate_beta_drf(x, lr):\n",
    "    return lr.fit(x[['mkt', 'DRF']], \n",
    "           x['return_daily'].fillna(0) - x['0.25']).coef_[1]\n",
    "\n",
    "for_beta_drf = [calculate_beta_drf(window, lr) for windows in tqdm(df_1.groupby('SECID').apply(\n",
    "lambda x:x.set_index('TRADEDATE')[['return_daily', 'mkt', 'DRF', '0.25']].rolling(40)))\n",
    "                for window in list(windows)]\n",
    "\n",
    "df_gr['BETA_DRF'] = for_beta_drf\n",
    "df_1 = df_1.join(df_gr['BETA_DRF'], on=['SECID', 'TRADEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add info on trades up to 10\n",
    "for i in range(5, 11):\n",
    "    df[f'CLOSE_{i}'] = df.groupby('SECID')['CLOSE'].shift(i)\n",
    "    df[f'VALUE_{i}'] = df.groupby('SECID')['VALUE'].shift(i)\n",
    "    df[f'DIST_{i}'] = (df['TRADEDATE'] - df.groupby('SECID')['TRADEDATE'].shift(i)).apply(lambda x:x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bound betas between 1st and 99th percentile\n",
    "df_1['BETA_ORD'] = (df_1['BETA_ORD'] > df_1['BETA_ORD'].quantile(0.99)).astype(int) * df_1['BETA_ORD'].quantile(0.99) + \\\n",
    "(df_1['BETA_ORD'] < df_1['BETA_ORD'].quantile(0.01)).astype(int) * df_1['BETA_ORD'].quantile(0.01) + \\\n",
    "df_1['BETA_ORD'].between(df_1['BETA_ORD'].quantile(0.01), df_1['BETA_ORD'].quantile(0.99)) * df_1['BETA_ORD']\n",
    "\n",
    "df_1['BETA_DEF'] = (df_1['BETA_DEF'] > df_1['BETA_DEF'].quantile(0.99)).astype(int) * df_1['BETA_DEF'].quantile(0.99) + \\\n",
    "(df_1['BETA_DEF'] < df_1['BETA_DEF'].quantile(0.01)).astype(int) * df_1['BETA_DEF'].quantile(0.01) + \\\n",
    "df_1['BETA_DEF'].between(df_1['BETA_DEF'].quantile(0.01), df_1['BETA_DEF'].quantile(0.99)) * df_1['BETA_DEF']\n",
    "\n",
    "df_1['BETA_TERM'] = ((df_1['BETA_TERM'] > df_1['BETA_TERM'].quantile(0.99)).astype(int) * df_1['BETA_TERM'].quantile(0.99) + \\\n",
    "(df_1['BETA_TERM'] < df_1['BETA_TERM'].quantile(0.01)).astype(int) * df_1['BETA_TERM'].quantile(0.01) + \\\n",
    "df_1['BETA_TERM'].between(df_1['BETA_TERM'].quantile(0.01), df_1['BETA_TERM'].quantile(0.99)) * df_1['BETA_TERM'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Machine learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
